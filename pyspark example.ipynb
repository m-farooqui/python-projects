{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcac0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#  Using this function as spark instance\n",
    "def spark_inst():\n",
    "    return SparkSession.builder.master(\"local[*]\")\\\n",
    "           .appName('Spark')\\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract.py\n",
    "# Read data from mysql database\n",
    "def extract(spark: SparkSession, type: str, source: str):\n",
    "# Read data from mysql database\n",
    "    if type==\"JDBC\":\n",
    "        output_df = spark.read.format(\"JDBC\").options(url='jdbc:mysql://localhost/world',dbtable=source,driver='com.mysql.cj.jdbc.Driver',user='root',password='root').load()\n",
    "        return output_df\n",
    "    # read data from filesystem\n",
    "    if type==\"CSV\":\n",
    "        output_df = spark.read.format(\"CSV\").options(header=True,inferSchema=True).load(source)\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab42bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant.py\n",
    "#Tranform the column by renaming them by using a dictionary. \n",
    "CITY_COL_DICT={\n",
    "     \"ID\": \"city_id\",\n",
    "     \"Name\": \"city_name\",\n",
    "     \"CountryCode\": \"country_code\",\n",
    "     \"District\": \"city_district\",\n",
    "     \"Population\": \"city_population\"\n",
    "}\n",
    "COUNTRY_COL_DICT={\n",
    "     \"Code\": \"country_code\",\n",
    "     \"Name\": \"country_name\",\n",
    "     \"Continent\": \"continent\",\n",
    "     \"Region\": \"region\",\n",
    "     \"SurfaceArea\": \"surface_area\",\n",
    "     \"IndepYear\": \"independence_year\",\n",
    "     \"Population\": \"country_population\",\n",
    "     \"LifeExpectancy\": \"life_expectancy\",\n",
    "     \"GNP\": \"gross_national_product\",\n",
    "     \"GNPOld\": \"old_gross_national_product\",\n",
    "     \"LocalName\": \"local_name\",\n",
    "     \"GovernmentForm\": \"government_form\",\n",
    "     \"HeadOfState\": \"head_of_state\",\n",
    "     \"Capital\": \"capital\",\n",
    "     \"Code2\": \"country_code_2\"\n",
    "}\n",
    "COUNTRY_LANGUAGE_COL_DICT={\n",
    "     \"CountryCode\": \"country_code\",\n",
    "     \"Language\": \"language\",\n",
    "     \"IsOfficial\": \"is_official_language\",\n",
    "     \"Percentage\": \"language_percentage\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2babe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a join operation on country code since its common in all dataframes\n",
    "# constant.py\n",
    "\n",
    "JOIN_ON_COLUMNS=['country_code']\n",
    "JOIN_TYPE=\"left\"\n",
    "SPEC_COLS=[\n",
    "     \"country_code\",\n",
    "     \"country_name\",\n",
    "     \"region\",\n",
    "     \"surface_area\",\n",
    "     \"independence_year\",\n",
    "     \"country_population\",\n",
    "     \"life_expectancy\",\n",
    "     \"local_name\",\n",
    "     \"head_of_state\",\n",
    "     \"capital\",\n",
    "     \"country_code_2\",\n",
    "     \"city_id\",\n",
    "     \"city_name\",\n",
    "     \"city_district\",\n",
    "     \"city_population\",\n",
    "     \"language\",\n",
    "     \"is_official_language\",\n",
    "     \"language_percentage\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5469f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load.py\n",
    "#Load the data in mysql and filesystem\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "def load(type: str, df: DataFrame, target: str):\n",
    "    # Load the data based on type\n",
    "    '''\n",
    "    :param type: Input Storage type (JDBC|CSV) Based on type data stored in MySQL or FileSystem\n",
    "    :param df: Input Dataframe\n",
    "    :param target: Input target \n",
    "             -For filesystem - Location where to store the data\n",
    "             -For MySQL - table name\n",
    "    '''\n",
    "\n",
    "    # Write data on mysql database with table name\n",
    "    if type==\"JDBC\":\n",
    "       df.write.format(\"JDBC\").mode(\"overwrite\")\\\n",
    ".options(url='jdbc:mysql://localhost/world',dbtable=target,driver='com.mysql.cj.jdbc.Driver',user='root',password='root').save()\n",
    "       print(f\"Data succesfully loaded to MySQL Database !!\")\n",
    "    \n",
    "    if type==\"CSV\":\n",
    "    # Write data on filesystem\n",
    "       df.write.format(\"CSV\").mode(\"overwrite\").options(header=True).save(target)\n",
    "       print(f\"Data succesfully loaded to filesystem !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992552c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To execute everything in ETL steps put all the functions together\n",
    "# Imported required libraries and modules\n",
    "from pyspark.sql import SparkSession\n",
    "from metadata.constant import CITY_COL_DICT, COUNTRY_LANGUAGE_COL_DICT, COUNTRY_COL_DICT, \\\n",
    "JOIN_TYPE,JOIN_ON_COLUMNS, SPEC_COLS, spark_inst\n",
    "from extract import extract\n",
    "from transform import rename_cols, join_df, specific_cols\n",
    "from load import load\n",
    "\n",
    "# Initiating and Calling SparkSession\n",
    "SPARK=spark_inst()\n",
    "\n",
    "#### Extract ####\n",
    "\n",
    "# Extracting CITY and COUNTRY data from MYSQL\n",
    "city_df = extract(SPARK,\"JDBC\",\"city\")\n",
    "country_df = extract(SPARK,\"JDBC\",\"country\")\n",
    "\n",
    "# Extracting COUNTRYLANGUAGE data from FileSystem\n",
    "country_language_df = extract(SPARK,\"CSV\",\"filesystem/countrylanguage.csv\")\n",
    "\n",
    "#### Transformation ####\n",
    "\n",
    "# 1. Rename Columns\n",
    "city_df = rename_cols(city_df, CITY_COL_DICT)\n",
    "country_df = rename_cols(country_df, COUNTRY_COL_DICT)\n",
    "country_language_df = rename_cols(country_language_df, COUNTRY_LANGUAGE_COL_DICT)\n",
    "\n",
    "# 2. Join DF with common column \"country_code\"\n",
    "country_city_df=join_df(country_df, city_df, JOIN_ON_COLUMNS, JOIN_TYPE)\n",
    "country_city_language_df= join_df(country_city_df, country_language_df, JOIN_ON_COLUMNS, JOIN_TYPE)\n",
    "\n",
    "# 3. Get specific cols\n",
    "country_city_language_df = specific_cols(country_city_language_df, SPEC_COLS)\n",
    "\n",
    "\n",
    "#### Load Data ####\n",
    "\n",
    "# MySQL\n",
    "load(\"JDBC\",country_city_language_df, \"CountryCityLanguage\")\n",
    "\n",
    "# FileSystem\n",
    "load(\"CSV\",country_city_language_df, \"output/countrycitylanguage.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
